{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2052eb76",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "> You can use the function `ProcessImage()` to segment and extract quantititative values from a single plate image. The default is to extract only size features, which include the patch area, average pixel intensity, sum of pixel intensities, and perimeter. However, you can also extract texture features which include the variance of pixel intensities, the \"complexity score\" of the patch, and 10 [local binary pattern scores](https://scikit-image.org/docs/stable/auto_examples/features_detection/plot_local_binary_pattern.html) reflecting performing the LBP transform with a neighborhood of 9 pixels. The complexity score is calculated by taking the sobel transform twice, summing over the patch area and then dividing by the patch area.\n",
    "\n",
    "\n",
    "## Function Use\n",
    "```\n",
    "df, tiles, masks, corners = PyPl8.ProcessImage(file, sourcefolder, outputfolder,\n",
    "                                               crop_method = 'Auto', crop_param = None, adjust = True, rotate = False, \n",
    "                                               s = 200, array_dimensions = (8,12), \n",
    "                                               pin_size = 25, features = 'size', save = True, \n",
    "                                               display = False, calibrate = False)\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "- **file:** *string (required)* Name of image to be processed including file extension\n",
    "- **sourcefolder:** *string (required)* Path to folder containing images to be processed\n",
    "- **outputfolder:** *string (required)* Path to desired location for function output to be saved. If the folder does not exist, it will be created during processing as long as it is a valid path. If you are using save = False, then you can provide a dummy variable like [] in place of a folder path. \n",
    "- **crop_method:** *string (optional)* There are 3 possible methods for pre-processing the images. The default value is `'Auto'`, which detects the agar plate by thresholding the whole image and then estimates pin locations based on the plate shape. This method generally works well when plates are placed parallel to the edges of the photo and the majority of patches have significant growth. It relies fairly heavily on the autoadjustment after initial guess, so if lots of patches are not growing well it fails because there is not a good reference point to adjust to. A second option is `'Grid'`, in which the user inputs the position of the center of patch A1 either through `crop_param` or upon viewing the image in the notebook. On a windows or mac operating system, you can also use the '`Click`' option, which will open the image in another window and you can click on the A1 location to provide the necessary reference point. See example notebook for more information on how to use the `Click` option.\n",
    "- **features:** *string (optional)* The default value is `'size'`, which will extract the area, average pixel intensity, total pixel sum, and perimeter of each patch. If you want to additionally extract texture features, set `features = 'all'`.\n",
    "- **pin_size:** *integer (optional)* Estimated minimum patch radius in pixels, which corresponds to the radius of the pin used to place cells. The default value is 25, which is the lowest size that has fit experimental data from the Dudley lab. For the funnel cross data, a pin size of 28 was used. If you set pin_size = 0, then during the segmentation step, otsu thresholding alone will be used and circle detection will be skipped. \n",
    "- **crop_param:** *tuple of integers (optional)* When using the `'Grid'` crop method you can enter an estimate of the location of the center of patch A1 in the form (row, column) instead of using the image display step. By default the value of crop_param is None, but a reference location of A1 = (600,600) is used. Note that the location (0,0) indicates the top left corner of the image.\n",
    "- **s:** *integer (optional)* The side length of desired square regions of interest in pixels. The default value is 200 pixels.\n",
    "- **array_dimensions:** *tuple of integers (optional)* The dimensions of the patch lay out on the plate in the form (number of rows, number of columns). The default value is (8,12). \n",
    "- **adjust:** *boolean (optional)* The default value is True. When True, adjust will perform a preliminary segmentation of each ROI and shift it so that the ROI is centered on the largest object in that intial area. If an ROI does not contain any detectable objects at this initial pass, it will be recentered based on the mean change in other patches in that row and column. For tricky images with lots of null growth I suggest carefully calibrating the reference point for the `Grid` cropping option, perhaps with a widget as shown below, and setting `adjust = False`. \n",
    "- **rotate:** *boolean (optional)* The default value is `False`. When `True`, plate images will be rotated 180 degrees before being processed. \n",
    "- **save:** *boolean (optional)* The default value is `True`. When `True`, the dataframe of quantitative outputs will be saved to the output folder as a csv file and the segmented image will be saved to the output folder as a jpg file. If `False`, nothing will be saved.\n",
    "- **display:** *boolean (optional)* The default value is `False`. When true, the segmented image will be displayed to the screen after processing. \n",
    "- **calibrate:** *boolean (optional)* The default value is `False`. If using `Grid` crop, you can set `calibrate = True` in order to see the image displayed in line and enter the location of the center of patch A1. Note that the location (0,0) indicates the top left corner of the image. \n",
    "\n",
    "### Returns\n",
    "- **dataframe:** *pandas dataframe* If you want to explore the output from image processing in the jupyter notebook, pandas can be useful. Each row corresponds to a patch and each column contains the specified features. \n",
    "- **tiles:** *list of grayscale images* In case you want to reference the images that correspond to the data points in the data frame, you can use this list of tiles. They are ordered the same way as the dataframe. \n",
    "- **masks:** *list of binary images* To segment the tiles and look at the segmentation that corresponds to each data point, multiply the masks and tiles together. \n",
    "- **corners:** *list of tuples* This is a list of the location of the top left corner of each tile within the original image. It is used when reconstructing the segmented images. \n",
    "\n",
    "## Examples\n",
    "\n",
    "### Example 1: Use 'Auto' cropping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d54a4c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PyPl8'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KATHER~1\\AppData\\Local\\Temp/ipykernel_15388/1168767736.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mPyPl8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mProcessImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimage_folder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr'C:\\Users\\Katherine\\Documents\\Python_Scripts\\TestPyPIVersion\\PyPl8-main\\New folder\\ExampleImages'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'YCR71P01_CF_24h_12-20-45.jpg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'PyPl8'"
     ]
    }
   ],
   "source": [
    "from PyPl8 import ProcessImage\n",
    "\n",
    "image_folder = r'C:\\Users\\Katherine\\Documents\\Python_Scripts\\TestPyPIVersion\\PyPl8-main\\New folder\\ExampleImages'\n",
    "file = 'YCR71P01_CF_24h_12-20-45.jpg'\n",
    "\n",
    "df, _ , _ , _ = ProcessImage(file, image_folder, None, save = False, display = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53622f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(df.Area, df.AvgInt, 'k.', markersize=1.25);\n",
    "plt.xlabel('Area')\n",
    "plt.ylabel('Average Pixel Intensity')\n",
    "list(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365fb82e",
   "metadata": {},
   "source": [
    "###  Example 2: Use the 'Grid' method without auto-adjustment to calibrate pre-segmentation cropping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0db3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = image_folder = '/home/user/ExampleImages'\n",
    "file = 'YCR71P01_GAL_24h_12-19-36.jpg'\n",
    "\n",
    "df, _ , _ , _ = ProcessImage(file, image_folder, None, \n",
    "                             crop_method = 'Grid', calibrate = True, adjust = False, \n",
    "                             save = False, display = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54731f11",
   "metadata": {},
   "source": [
    "### Example 3: Use a widget to click on image to collect reference point for cropping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3730426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from skimage import io\n",
    "from skimage.io import imread\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import ipywidgets as wdg \n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define a click function that will record the reference point indicated and display the corresponding tiles\n",
    "def onclick(event):\n",
    "    global clickcount, refPt\n",
    "    if clickcount == 0:  \n",
    "        clickcount +=1\n",
    "        temp = str(event).split('(')[2]\n",
    "        temp1 = temp.split(')')[0]\n",
    "        temp2 = temp1.split(' ')[0]\n",
    "        temp3 = temp2.rstrip(temp2[-1])\n",
    "        temp4 = temp1.split(' ')[1]\n",
    "        refPt = (round(float(temp4)),round(float(temp3)))# Update the reference point\n",
    "        ax.plot(round(float(temp3)),round(float(temp4)),'r.') # plot clicked point\n",
    "        # Plot tile boundaries\n",
    "        s = 200\n",
    "        r1 = round(float(temp4))\n",
    "        r2 = r1 + (8-1/2)*s # 8 is the number of rows\n",
    "        c1 = round(float(temp3))\n",
    "        c2 = c1 + (12- 1/2)*s*1.02 # 12 is the number of columns\n",
    "        rps = np.linspace(r1,r2,8)\n",
    "        cps = np.linspace(c1,c2,12)\n",
    "\n",
    "        for r in rps:\n",
    "            for c in cps:\n",
    "                r1 = int(r-s/2)\n",
    "                c1 = int(c-s/2)\n",
    "                rect = patches.Rectangle((c1, r1), s, s, linewidth=1.2, edgecolor='b', facecolor='none')\n",
    "                ax.add_patch(rect)        \n",
    "    else:\n",
    "        fig.canvas.mpl_disconnect(cid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592642a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import image\n",
    "os.chdir(image_folder)\n",
    "file = 'YCR71P01_GAL_24h_12-19-36.jpg'\n",
    "image = io.imread(file)\n",
    "\n",
    "#Show the image with matplotlib\n",
    "clickcount = 0\n",
    "refPt = None\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (8,6));\n",
    "ax.imshow(image)\n",
    "ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Collect user input\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5ac605",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(refPt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61f20e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "df, _ , _ , _ = ProcessImage(file, image_folder, None, \n",
    "                             crop_method = 'Grid', crop_param = refPt, calibrate = False,\n",
    "                             pin_size = 32, save = False, display = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fde8b8",
   "metadata": {},
   "source": [
    "### Example 4: Test different pin sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3355b75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [25, 28, 31]:\n",
    "    df, _ , _ , _ = ProcessImage('YCR71P01_GAL_24h_12-19-36.jpg', image_folder, None, pin_size = p,\n",
    "                                 crop_method = 'Grid', crop_param = refPt, calibrate = False,\n",
    "                                 save = False, display = False)\n",
    "    plt.plot(df.Area, df.AvgInt, '.');\n",
    "    plt.xlabel('Area')\n",
    "    plt.ylabel('Average Pixel Intensity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34e409f",
   "metadata": {},
   "source": [
    "### Example 5: Use intensity thresholding without circle detection for thresholding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd13d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'YCR71P01_GAL_24h_12-19-36.jpg'\n",
    "\n",
    "df, _ , _ , _ = ProcessImage(file, image_folder, None, crop_method = 'Grid', calibrate = True, \n",
    "                             save = False, display = True, pin_size = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4e22be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, _ , _ , _ = ProcessImage(file, image_folder, None, crop_method = 'Grid', crop_param = (600,575), \n",
    "                             save = False, display = True, pin_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd2076d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
